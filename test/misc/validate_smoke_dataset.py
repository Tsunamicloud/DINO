import json
import torch
import numpy as np
from pathlib import Path

def validate_coco_annotations(ann_file):
    """éªŒè¯COCOæ ¼å¼æ ‡æ³¨æ–‡ä»¶"""
    print(f"æ­£åœ¨éªŒè¯: {ann_file}")
    
    with open(ann_file, 'r') as f:
        data = json.load(f)
    
    print(f"å›¾åƒæ•°é‡: {len(data['images'])}")
    print(f"æ ‡æ³¨æ•°é‡: {len(data['annotations'])}")
    print(f"ç±»åˆ«æ•°é‡: {len(data['categories'])}")
    
    # æ£€æŸ¥ç±»åˆ«ID
    category_ids = [cat['id'] for cat in data['categories']]
    print(f"ç±»åˆ«IDèŒƒå›´: {min(category_ids)} - {max(category_ids)}")
    print(f"ç±»åˆ«IDåˆ—è¡¨: {sorted(category_ids)}")
    
    # æ£€æŸ¥æ ‡æ³¨
    invalid_boxes = []
    invalid_categories = []
    
    for i, ann in enumerate(data['annotations']):
        # æ£€æŸ¥bboxæ ¼å¼ [x, y, width, height]
        bbox = ann['bbox']
        x, y, w, h = bbox
        
        # æ£€æŸ¥bboxæœ‰æ•ˆæ€§
        if w <= 0 or h <= 0:
            invalid_boxes.append({
                'annotation_id': ann['id'],
                'bbox': bbox,
                'issue': f'å®½åº¦æˆ–é«˜åº¦ <= 0: w={w}, h={h}'
            })
        
        if x < 0 or y < 0:
            invalid_boxes.append({
                'annotation_id': ann['id'], 
                'bbox': bbox,
                'issue': f'åæ ‡ä¸ºè´Ÿ: x={x}, y={y}'
            })
        
        # æ£€æŸ¥ç±»åˆ«ID
        if ann['category_id'] not in category_ids:
            invalid_categories.append({
                'annotation_id': ann['id'],
                'category_id': ann['category_id'],
                'issue': 'ç±»åˆ«IDä¸åœ¨å®šä¹‰çš„ç±»åˆ«ä¸­'
            })
    
    # æŠ¥å‘Šé—®é¢˜
    if invalid_boxes:
        print(f"\nâŒ å‘ç° {len(invalid_boxes)} ä¸ªæ— æ•ˆbbox:")
        for issue in invalid_boxes[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            print(f"  - æ ‡æ³¨ID {issue['annotation_id']}: {issue['issue']}")
        if len(invalid_boxes) > 5:
            print(f"  - ... è¿˜æœ‰ {len(invalid_boxes) - 5} ä¸ªæ— æ•ˆbbox")
    else:
        print("\nâœ… æ‰€æœ‰bboxæ ¼å¼æ­£ç¡®")
    
    if invalid_categories:
        print(f"\nâŒ å‘ç° {len(invalid_categories)} ä¸ªæ— æ•ˆç±»åˆ«:")
        for issue in invalid_categories[:5]:
            print(f"  - æ ‡æ³¨ID {issue['annotation_id']}: ç±»åˆ«ID {issue['category_id']}")
    else:
        print("\nâœ… æ‰€æœ‰ç±»åˆ«IDæ­£ç¡®")
    
    return len(invalid_boxes) == 0 and len(invalid_categories) == 0

def main():
    """éªŒè¯çƒŸé›¾æ•°æ®é›†"""
    print("=== çƒŸé›¾æ•°æ®é›†éªŒè¯å·¥å…· ===\n")
    
    dataset_path = Path("./coco_smoke_merged")
    
    # éªŒè¯è®­ç»ƒé›†
    train_ann = dataset_path / "annotations" / "instances_train2017.json"
    if train_ann.exists():
        train_valid = validate_coco_annotations(train_ann)
    else:
        print(f"âŒ è®­ç»ƒé›†æ ‡æ³¨æ–‡ä»¶ä¸å­˜åœ¨: {train_ann}")
        train_valid = False
    
    print("\n" + "="*50 + "\n")
    
    # éªŒè¯éªŒè¯é›†
    val_ann = dataset_path / "annotations" / "instances_val2017.json"
    if val_ann.exists():
        val_valid = validate_coco_annotations(val_ann)
    else:
        print(f"âŒ éªŒè¯é›†æ ‡æ³¨æ–‡ä»¶ä¸å­˜åœ¨: {val_ann}")
        val_valid = False
    
    print("\n" + "="*50)
    print("éªŒè¯æ€»ç»“:")
    print(f"è®­ç»ƒé›†: {'âœ… é€šè¿‡' if train_valid else 'âŒ æœ‰é—®é¢˜'}")
    print(f"éªŒè¯é›†: {'âœ… é€šè¿‡' if val_valid else 'âŒ æœ‰é—®é¢˜'}")
    
    if not (train_valid and val_valid):
        print("\nâš ï¸ æ•°æ®é›†å­˜åœ¨é—®é¢˜ï¼Œéœ€è¦ä¿®å¤åæ‰èƒ½è®­ç»ƒ")
        return False
    else:
        print("\nğŸ‰ æ•°æ®é›†éªŒè¯é€šè¿‡ï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒï¼")
        return True

if __name__ == "__main__":
    main()