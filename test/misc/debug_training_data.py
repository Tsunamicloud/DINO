import json
import torch
import numpy as np
from pathlib import Path
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('.')

from datasets import build_dataset
from util.box_ops import box_cxcywh_to_xyxy
import argparse

def create_debug_args():
    """åˆ›å»ºè°ƒè¯•ç”¨çš„å‚æ•°"""
    args = argparse.Namespace()
    args.coco_path = './coco_smoke_merged'
    args.dataset_file = 'coco'
    args.masks = False
    args.fix_size = False
    args.strong_aug = False
    args.data_aug_scales = [480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800]
    args.data_aug_max_size = 1333
    args.data_aug_scales2_resize = [400, 500, 600]
    args.data_aug_scales2_crop = [384, 600]
    args.data_aug_scale_overlap = None
    return args

def check_bbox_validity(boxes, name=""):
    """æ£€æŸ¥bboxçš„æœ‰æ•ˆæ€§"""
    issues = []
    
    if boxes.numel() == 0:
        return issues
        
    # æ£€æŸ¥NaNå’ŒInf
    if torch.isnan(boxes).any():
        issues.append(f"{name}: åŒ…å«NaNå€¼")
    if torch.isinf(boxes).any():
        issues.append(f"{name}: åŒ…å«Infå€¼")
    
    # æ£€æŸ¥èŒƒå›´
    if (boxes < 0).any():
        issues.append(f"{name}: åŒ…å«è´Ÿå€¼")
    if (boxes > 1.1).any():  # å…è®¸ä¸€äº›æ•°å€¼è¯¯å·®
        issues.append(f"{name}: åŒ…å«è¶…è¿‡1çš„å€¼")
    
    # æ£€æŸ¥bboxæ ¼å¼ (cx, cy, w, h)
    cx, cy, w, h = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]
    if (w <= 0).any():
        issues.append(f"{name}: å®½åº¦ <= 0")
    if (h <= 0).any():
        issues.append(f"{name}: é«˜åº¦ <= 0")
    
    # æ£€æŸ¥è½¬æ¢åçš„xyxyæ ¼å¼
    try:
        boxes_xyxy = box_cxcywh_to_xyxy(boxes)
        x1, y1, x2, y2 = boxes_xyxy[:, 0], boxes_xyxy[:, 1], boxes_xyxy[:, 2], boxes_xyxy[:, 3]
        if (x2 <= x1).any():
            issues.append(f"{name}: x2 <= x1")
        if (y2 <= y1).any():
            issues.append(f"{name}: y2 <= y1")
    except Exception as e:
        issues.append(f"{name}: è½¬æ¢åˆ°xyxyæ—¶å‡ºé”™: {e}")
    
    return issues

def debug_single_sample(dataset, idx):
    """è°ƒè¯•å•ä¸ªæ ·æœ¬"""
    print(f"\n{'='*50}")
    print(f"è°ƒè¯•æ ·æœ¬ #{idx}")
    print(f"{'='*50}")
    
    try:
        img, target = dataset[idx]
        
        print(f"å›¾åƒå½¢çŠ¶: {img.shape}")
        print(f"å›¾åƒç±»å‹: {img.dtype}")
        print(f"å›¾åƒå€¼èŒƒå›´: [{img.min():.3f}, {img.max():.3f}]")
        
        print(f"\nç›®æ ‡ä¿¡æ¯:")
        for key, value in target.items():
            if isinstance(value, torch.Tensor):
                print(f"  {key}: shape={value.shape}, dtype={value.dtype}")
                if key == 'boxes':
                    print(f"    bboxå€¼èŒƒå›´: [{value.min():.3f}, {value.max():.3f}]")
                    issues = check_bbox_validity(value, "boxes")
                    if issues:
                        print(f"    âŒ å‘ç°é—®é¢˜: {', '.join(issues)}")
                        return False
                    else:
                        print(f"    âœ… bboxæ ¼å¼æ­£ç¡®")
                elif key == 'labels':
                    unique_labels = torch.unique(value)
                    print(f"    æ ‡ç­¾: {unique_labels.tolist()}")
                    if (value < 0).any() or (value >= 1).any():  # çƒŸé›¾æ•°æ®é›†åªæœ‰1ä¸ªç±»åˆ«ï¼Œæ ‡ç­¾åº”è¯¥æ˜¯0
                        print(f"    âŒ æ ‡ç­¾è¶…å‡ºèŒƒå›´ [0, 0]: {value.tolist()}")
                        return False
            else:
                print(f"  {key}: {value}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¤„ç†æ ·æœ¬æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»è°ƒè¯•å‡½æ•°"""
    print("=== DINOè®­ç»ƒæ•°æ®è°ƒè¯•å·¥å…· ===\n")
    
    # åˆ›å»ºå‚æ•°
    args = create_debug_args()
    
    # æ„å»ºæ•°æ®é›†
    print("ğŸ” æ„å»ºè®­ç»ƒæ•°æ®é›†...")
    try:
        dataset = build_dataset('train', args)
        print(f"âœ… æ•°æ®é›†å¤§å°: {len(dataset)}")
    except Exception as e:
        print(f"âŒ æ„å»ºæ•°æ®é›†å¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•å‰å‡ ä¸ªæ ·æœ¬
    print(f"\nğŸ§ª æµ‹è¯•å‰10ä¸ªæ ·æœ¬...")
    failed_samples = []
    
    for i in range(min(10, len(dataset))):
        success = debug_single_sample(dataset, i)
        if not success:
            failed_samples.append(i)
    
    # éšæœºæµ‹è¯•ä¸€äº›æ ·æœ¬
    print(f"\nğŸ² éšæœºæµ‹è¯•10ä¸ªæ ·æœ¬...")
    import random
    random_indices = random.sample(range(len(dataset)), min(10, len(dataset)))
    
    for idx in random_indices:
        success = debug_single_sample(dataset, idx)
        if not success:
            failed_samples.append(idx)
    
    print(f"\n{'='*50}")
    print("è°ƒè¯•æ€»ç»“:")
    if failed_samples:
        print(f"âŒ å¤±è´¥çš„æ ·æœ¬: {failed_samples}")
        print(f"âŒ æ€»å…±æµ‹è¯•äº† {20} ä¸ªæ ·æœ¬ï¼Œå¤±è´¥äº† {len(failed_samples)} ä¸ª")
        return False
    else:
        print(f"âœ… æ‰€æœ‰æµ‹è¯•æ ·æœ¬éƒ½æ­£å¸¸")
        print(f"âœ… æ•°æ®é¢„å¤„ç†æµç¨‹æ­£ç¡®")
        return True

if __name__ == "__main__":
    success = main()
    if not success:
        print(f"\nğŸ’¡ å»ºè®®:")
        print(f"1. æ£€æŸ¥æ•°æ®é¢„å¤„ç†pipeline")
        print(f"2. æ£€æŸ¥ç±»åˆ«æ ‡ç­¾æ˜ å°„")
        print(f"3. å¯ç”¨CUDA_LAUNCH_BLOCKING=1è¿›è¡Œè¯¦ç»†è°ƒè¯•")